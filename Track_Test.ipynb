{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import random\n",
    "import time\n",
    "import imutils\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from matplotlib.patches import Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to implement tracking on one video sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this runs once per clip per tracker per resize value\n",
    "# lists declared and modified here pertain to one clip\n",
    "def run_track(tracker_name, tracker_inst, video_name, video_file, frames_df, resize):\n",
    "    '''\n",
    "    Runs a specified tracking algorithm on a specified video \\\n",
    "    file and evaluates tracker performance by comparing system \\\n",
    "    output to specified ground truth bounding boxes.\n",
    "    \n",
    "    Parameters:\n",
    "    \n",
    "    tracker_name (str): short name of tracking algo\n",
    "    tracker_inst: instantiation of tracker class\n",
    "    video_file: (str): path to video file\n",
    "    frames_df (pd.DataFrame): DF of ground truth objects in video clip\n",
    "    resize (int): fraction to which video should be resized (1, 2 or 4). 1 = unchanged (Def), 2 = 1/2, 4 = 1/4\n",
    "    '''\n",
    "    \n",
    "    # CONSTANTS\n",
    "    THRESHOLD_IOU, THRESHOLD_DIST = 0.4, 0.2\n",
    "    \n",
    "    # initialise vars\n",
    "    frame_count = frames_df['frame'].min() # works fine\n",
    "    fn_count, fp_count, fp_thresh_count, tp_count, tn_count, covered_count = 0, 0, 0, 0, 0, 0 # seem to work fine\n",
    "    tracking_fps = 0 # seems to work fine\n",
    "    iou_list, dist_list = [], [] # seems to work fine\n",
    "    tracker = None # presumably fine\n",
    "    writer = None # works\n",
    "    draw = False # works\n",
    "    \n",
    "    # Initialize the video stream and pointer to output video file\n",
    "    vs = cv2.VideoCapture(video_file)\n",
    "    \n",
    "    # start clock for FPS\n",
    "    tracker_time = start_timer()\n",
    "    \n",
    "    while True:\n",
    "        # read the next frame from the file\n",
    "        grabbed, frame = vs.read()\n",
    "        \n",
    "        # if no frame grabbed, reached end of clip\n",
    "        if not grabbed:\n",
    "            print ('[INFO] End of clip')\n",
    "            break\n",
    "        \n",
    "        # boolean for whether there is a ground truth object in the frame\n",
    "        object_exists = (frames_df['frame'] == frame_count).any()\n",
    "\n",
    "        if resize is not 0:\n",
    "            frame = cv2.resize(frame, (resize, int(resize*(9/16))))\n",
    "            \n",
    "        # will resize the frame for faster processing\n",
    "        new_width = frame.shape[1]\n",
    "        new_height = frame.shape[0]\n",
    "        \n",
    "        # number of rows in frames determine number of objects, N_objects\n",
    "        N_objects = len(frames_df.index)\n",
    "        \n",
    "        # bb for ground truth obj (relative values)\n",
    "        gt_bb = (frames_df.loc[frames_df['frame'] == frame_count].squeeze()[1:])*(new_width, new_height, new_width, new_height) if object_exists else 0\n",
    "        print('[INFO] gt_bb is: \\n')\n",
    "        \n",
    "        # initialize the writer\n",
    "        if writer is None:\n",
    "            print()\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            fps = vs.get(5)\n",
    "            # writer = cv2.VideoWriter('test_writer.mp4', fourcc, fps, (frame.shape[1], frame.shape[0]), True)\n",
    "            writer = cv2.VideoWriter('./output/' + video_name + '_' + tracker_name + \\\n",
    "                                     '_' + str(new_width) + '.mp4', fourcc, fps, \\\n",
    "                                     (frame.shape[1], frame.shape[0]), True)\n",
    "        \n",
    "        if tracker is None:\n",
    "            #print ('[INFO] Create tracker instance')\n",
    "            # create tracker object\n",
    "            tracker = tracker_inst\n",
    "            \n",
    "            # initialise with bounding box\n",
    "            tracker.init(frame, tuple(gt_bb))\n",
    "            \n",
    "        if tracker is not None:\n",
    "            # update the tracker and grab the tracked object\n",
    "            tracking, trk_bb = tracker.update(frame)\n",
    "            \n",
    "            # will need modifications for trackers outside of OpenCV-8\n",
    "            if tracking is None:\n",
    "                #print ('[INFO] tracking is none')\n",
    "                if ~object_exists:\n",
    "                    # true negative\n",
    "                    tn_count += 1\n",
    "                    \n",
    "                elif object_exists:\n",
    "                    # false negative\n",
    "                    fn_count += 1\n",
    "\n",
    "            elif tracking:\n",
    "                draw = True\n",
    "                if object_exists:\n",
    "                    iou_t, dist_t = compute_iou_dist(gt_bb, trk_bb) # pass them in (x1, y1, w, h) format\n",
    "                    \n",
    "                    # completeness metrics\n",
    "                    if iou_t >= THRESHOLD_IOU:\n",
    "                        covered_count += 1\n",
    "                    \n",
    "                    if dist_t < THRESHOLD_DIST:\n",
    "                        # false positive\n",
    "                        fp_thresh_count += 1\n",
    "                        \n",
    "                    elif dist_t >= THRESHOLD_DIST:\n",
    "                        # true positive\n",
    "                        tp_count += 1\n",
    "                        \n",
    "                    iou_list.append(iou_t)\n",
    "                    dist_list.append(dist_t)\n",
    "                    \n",
    "                elif ~object_exists:\n",
    "                    # false positive\n",
    "                    fp_count += 1\n",
    "                \n",
    "                # tracking taken place, so draw frame\n",
    "                if draw:\n",
    "                    p1 = (int(trk_bb[0]), int(trk_bb[1]))\n",
    "                    p2 = (int(trk_bb[0] + trk_bb[2]), int(trk_bb[1] + trk_bb[3]))\n",
    "                    cv2.rectangle(frame, p1, p2, (255, 0, 0), 2, 1)\n",
    "        \n",
    "        # increment frame counter\n",
    "        frame_count += 1\n",
    "        \n",
    "        # write the frame to disk\n",
    "        if writer is not None:\n",
    "            writer.write(frame)\n",
    "    \n",
    "    # finalise FPS\n",
    "    tracking_fps = stop_and_report(frame_count, tracker_time)\n",
    "    \n",
    "    if writer is not None:\n",
    "        writer.release()\n",
    "        \n",
    "    # print('[INFO] Res at end of loop: ' + str(frame.shape[:2]))\n",
    "        \n",
    "    # call metrics function - returns dictionary of metrics\n",
    "    metrics = compute_metrics(fp_thresh_count, fp_count, tp_count, tn_count, fn_count, \\\n",
    "                              covered_count, dist_list, iou_list, N_objects, frame_count, \\\n",
    "                              tracking_fps, clip_name, str(new_width), tracker_name)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_timer():\n",
    "    return time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_and_report(frames, start_time):\n",
    "    return frames/(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "This section defines functions to compute the various evaluation metrics detailed in Chapter 3 in the report. The metrics to compute are as follows:\n",
    "- Recall: Correctly matched detections as proportion of total ground truth objects (of a sequence).\n",
    "- Precision/N-SODA: Correctly matched detections as a proportion of total detections (of a sequence).\n",
    "- FAF: Number of false alarms (incorrect detections) per frame averaged over a sequence.\n",
    "- SODP: Average overlap between ground truth and system output.\n",
    "- SOTA: Combines false negatives and false positives without weighting factors.\n",
    "- SOTP: Average distance between centroids of ground truth and system output.\n",
    "- TDE: Distance beetween the ground-truth annotation and the tracking result.\n",
    "- MT: The ground-truth trajectory is covered by the tracker output for more than 80% of its length.\n",
    "- ML: The ground-truth trajectory is covered by the tracker output for less than 20% of its length.\n",
    "- PT: The ground-truth trajectory is covered by the tracker output for between 20% and 80% of its length.\n",
    "- FM: Number of times that a ground-truth trajectory is interrupted in the tracking result, normalised over sequence.\n",
    "- RS: Ratio of tracks which correctly recover from short term occlusion.\n",
    "- RL: Ratio of tracks which correctly recover from long term occlusion.\n",
    "\n",
    "### Terminology\n",
    "- **Success**: aka True Positive. Overlap between ground truth and tracker hypothesis is non-zero and within threshold.\n",
    "- **Success**: aka True Negative. No object and no hypothesis.\n",
    "- **Miss**: aka False Negative. No hypothesis from tracker.\n",
    "- **False Positive**: Overlap between tracker output and ground truth is less than threshold.\n",
    "- **Distance**: Euclidean distance between centroids of tracker output and ground truth.\n",
    "- **Covered**: Overlap exceeds THRESHOLD_IOU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Compute Each Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intersection over Union (IoU) and Distance Between Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou_dist(box_a, box_b):\n",
    "    \n",
    "    # compute centroids (x1 + half width, y1 + half height)\n",
    "    centroid_a = (box_a[0] + 0.5*box_a[2], box_a[1] + 0.5*box_a[3])\n",
    "    centroid_b = (box_b[0] + 0.5*box_b[2], box_b[1] + 0.5*box_b[3])\n",
    "    \n",
    "    # (x1, y1, x1+w, y1+h) -> (x1, y1, x2, y2)\n",
    "    box_a = (box_a[0], box_a[1], box_a[0] + box_a[2], box_a[1] + box_a[3])\n",
    "    box_b = (box_b[0], box_b[1], box_b[0] + box_b[2], box_b[1] + box_b[3])\n",
    "    \n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    x_a = max(box_a[0], box_b[0])\n",
    "    y_a = max(box_a[1], box_b[1])\n",
    "    x_b = min(box_a[2], box_b[2])\n",
    "    y_b = min(box_a[3], box_b[3])\n",
    "\n",
    "    # compute the area of intersection rectangle\n",
    "    area_overlap = max(0, x_b - x_a + 1) * max(0, y_b - y_a + 1)\n",
    "\n",
    "    # compute the area of both the prediction and ground-truth rectangles\n",
    "    area_box_a = (box_a[2] - box_a[0] + 1) * (box_a[3] - box_a[1] + 1)\n",
    "    area_box_b = (box_b[2] - box_b[0] + 1) * (box_b[3] - box_b[1] + 1)\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = area_overlap / float(area_box_a + area_box_b - area_overlap)\n",
    "    \n",
    "    # distance is hypotenuse of two centroid coordinates\n",
    "    dist = math.hypot(centroid_b[0] - centroid_a[0], centroid_b[1] - centroid_a[1])\n",
    "\n",
    "    # return the intersection over union value\n",
    "    return iou, dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. SOTP - Single Object Tracking Precision, or Average Distance\n",
    "Average distance between boxes only on frames with both an object and a hypothesis, i.e.:\n",
    "- `fp_thresh_count`\n",
    "- `tp_count`\n",
    "\n",
    "`dist_t` should be forced to zero for frames with any results outside of the above (fp, tn, fn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_sotp(dist_list, N_match):\n",
    "    total_dist = sum(dist_list)\n",
    "    return (total_dist/N_match) if N_match != 0 else np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. SOTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_sota(fp_thresh_count, fp_count, fn_count, N_objects):\n",
    "    return 1 - (fp_thresh_count + fp_count + fn_count)/(N_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_recall(tp_count, N_objects):\n",
    "    return tp_count/N_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_precision(tp_count, fp_thresh_count, fp_count):\n",
    "    return tp_count/(tp_count + fp_count + fp_thresh_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. FPF, False Positives per Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_fpf(fp_count, fp_thresh_count, N_frames):\n",
    "    return (fp_count + fp_thresh_count)/N_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. SODP, Single Object Detection Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_sodp(iou_list, N_match):\n",
    "    total_iou = sum(iou_list)\n",
    "    return (total_iou/N_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. MT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_mt(completeness):\n",
    "    return 1 if completeness >= 0.8 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_pt(completeness):\n",
    "    return 1 if (completeness > 0.2) and (completeness < 0.8) else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_ml(completeness):\n",
    "    return 1 if completeness <= 0.2 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. FM, Fragmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_fm(fp_thresh_count, fp_count, fn_count, N_objects):\n",
    "    return (fp_thresh_count + fp_count + fn_count)/(N_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Function\n",
    "This function calculates all metrics and returns them in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(fp_thresh_count, fp_count, tp_count, tn_count, fn_count, \\\n",
    "                    covered_count, dist_list, iou_list, N_objects, N_frames, \\\n",
    "                    tracking_fps, clip_name, width, tracker_name):\n",
    "    \n",
    "    N_match = fp_thresh_count + tp_count\n",
    "    completeness = covered_count/N_match if N_match != 0 else 0\n",
    "    \n",
    "    sotp = metric_sotp(dist_list, N_match)\n",
    "    sota = metric_sota(fp_thresh_count, fp_count, fn_count, N_objects)\n",
    "    recall = metric_recall(tp_count, N_objects)\n",
    "    precision = metric_precision(tp_count, fp_thresh_count, fp_count)\n",
    "    fpf = metric_fpf(fp_count, fp_thresh_count, N_frames)\n",
    "    sodp = metric_sodp(iou_list, N_match)\n",
    "    mt = metric_mt(completeness)\n",
    "    pt = metric_pt(completeness)\n",
    "    ml = metric_ml(completeness)\n",
    "    fm = metric_fm(fp_thresh_count, fp_count, fn_count, N_objects)\n",
    "    \n",
    "    results_dict = {'Clip': clip_name,\n",
    "                    'Res': width,\n",
    "                    'Tracker': tracker_name,\n",
    "                    'SOTP': np.round(sotp,4),\n",
    "                    'SOTA': np.round(sota,4),\n",
    "                    'Recall': np.round(recall,4),\n",
    "                    'Precision': np.round(precision,4),\n",
    "                    'FPF': np.round(fpf, 4),\n",
    "                    'SODP': np.round(sodp,4),\n",
    "                    'MT': mt,\n",
    "                    'PT': pt,\n",
    "                    'ML': ml,\n",
    "                    'Completeness': np.round(completeness,2),\n",
    "                    'FM': np.round(fm,2),\n",
    "                    'FPS': np.round(tracking_fps,2),\n",
    "                    'fp_count': fp_count,\n",
    "                    'fp_thresh_count': fp_thresh_count,\n",
    "                    'tp_count': tp_count,\n",
    "                    'fn_count': fn_count,\n",
    "                    'tn_count': tn_count,\n",
    "                    'N_objects': N_objects,\n",
    "                    'N_frames': N_frames,\n",
    "                    'N_match': N_match}\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of trackers to run through for each video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trackers = {'boosting': cv2.TrackerBoosting_create(),\n",
    "#                 'mil': cv2.TrackerMIL_create(),\n",
    "#                 'kcf': cv2.TrackerKCF_create(),\n",
    "#                 'tld': cv2.TrackerTLD_create(),\n",
    "#                 'medianflow': cv2.TrackerMedianFlow_create(),\n",
    "#                 'goturn': cv2.TrackerGOTURN_create(),\n",
    "#                 'mosse': cv2.TrackerMOSSE_create(),\n",
    "#                 'csrt': cv2.TrackerCSRT_create()}\n",
    "#                 # 're3': re3_tracker.Re3Tracker(),\n",
    "#                 # 'pysot': base_tracker.BaseTracker()}\n",
    "        \n",
    "trackers = {'medianflow': cv2.TrackerMedianFlow_create()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clips = {'Bike02': '/Users/kierandonnelly/thesis/raw_clips/Bike02.mp4',\n",
    "#         'Bike03': '/Users/kierandonnelly/thesis/raw_clips/Bike03.mp4',\n",
    "#         'Bike04': '/Users/kierandonnelly/thesis/raw_clips/Bike04.mp4',\n",
    "#         'Bike05': '/Users/kierandonnelly/thesis/raw_clips/Bike05.mp4',\n",
    "#         'Bike07': '/Users/kierandonnelly/thesis/raw_clips/Bike07.mp4',\n",
    "#         'Bike08': '/Users/kierandonnelly/thesis/raw_clips/Bike08.mp4',\n",
    "#         'Bike09': '/Users/kierandonnelly/thesis/raw_clips/Bike09.mp4',\n",
    "#         'Ski01': '/Users/kierandonnelly/thesis/raw_clips/Ski01.mp4',\n",
    "#         'Ski02': '/Users/kierandonnelly/thesis/raw_clips/Ski02.mp4',\n",
    "#         'Ski03': '/Users/kierandonnelly/thesis/raw_clips/Ski03.mp4',\n",
    "#         'Ski04': '/Users/kierandonnelly/thesis/raw_clips/Ski04.mp4',\n",
    "#         'Snowboard01': '/Users/kierandonnelly/thesis/raw_clips/Snowboard01.mp4',\n",
    "#         'Sup01': '/Users/kierandonnelly/thesis/raw_clips/Sup01.mp4',\n",
    "#         'Surf01': '/Users/kierandonnelly/thesis/raw_clips/Surf01.mp4',\n",
    "#         'Wake01': '/Users/kierandonnelly/thesis/raw_clips/Wake01.mp4',\n",
    "#         'Car01': '/Users/kierandonnelly/thesis/raw_clips/Car01.mp4',\n",
    "#         'Human01': '/Users/kierandonnelly/thesis/raw_clips/Human01.mp4',\n",
    "#         'Slalom01': '/Users/kierandonnelly/thesis/raw_clips/Slalom01.mp4'}\n",
    "\n",
    "clips = {'Sup01': '/Users/kierandonnelly/thesis/raw_clips/Sup01.mp4',\n",
    "        'Snowboard01': '/Users/kierandonnelly/thesis/raw_clips/Snowboard01.mp4'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize = (1,2,4)\n",
    "\n",
    "# resize = [0, 1280, 640]\n",
    "\n",
    "resize = [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over videos in directory and run tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = []\n",
    "\n",
    "# iterate over clips\n",
    "for clip_name, clip_loc in clips.items(): \n",
    "    print('[INFO] Clip name: ' + str(clip_name))\n",
    "    \n",
    "    # retrieve frame data for clip\n",
    "    frames = pd.read_csv('./frame_data/' + str(clip_name) + '.csv', sep=';')\n",
    "    \n",
    "    # iterate over tracker dictionary\n",
    "    for tracker_name, tracker_inst in trackers.items():\n",
    "        \n",
    "        for i in resize:\n",
    "            # call tracking function\n",
    "            metrics = run_track(tracker_name, tracker_inst, clip_name, clip_loc, frames, i)\n",
    "            \n",
    "            metrics_list.append(metrics)\n",
    "    \n",
    "# convert list of metrics dicts to df\n",
    "results_df = pd.DataFrame(metrics_list, columns=['Clip', 'Res', 'Tracker', 'SOTP', 'SOTA', 'Recall',\\\n",
    "                                                 'Precision', 'FPF', 'SODP', 'MT', 'PT', 'ML', 'Completeness',\\\n",
    "                                                 'FM', 'FPS', 'fp_count', 'fp_thresh_count', 'tp_count',\\\n",
    "                                                 'fn_count', 'tn_count', 'N_objects', 'N_frames', 'N_match'])\n",
    "\n",
    "# save to CSV\n",
    "results_df.to_csv('metrics_' + time.strftime('%l:%M:%S' + '.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Thesis Env",
   "language": "python",
   "name": "thesis_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
