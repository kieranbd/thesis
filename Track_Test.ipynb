{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boring technical stuff\n",
    "import os, sys\n",
    "import random\n",
    "import time\n",
    "import imutils\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from matplotlib.patches import Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of trackers to run through for each video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackers = {'boosting': cv2.TrackerBoosting_create(),\n",
    "                'mil': cv2.TrackerMIL_create(),\n",
    "                'kcf': cv2.TrackerKCF_create(),\n",
    "                'tld': cv2.TrackerTLD_create(),\n",
    "                'medianflow': cv2.TrackerMedianFlow_create(),\n",
    "                'goturn': cv2.TrackerGOTURN_create(),\n",
    "                'mosse': cv2.TrackerMOSSE_create(),\n",
    "                'csrt': cv2.TrackerCSRT_create()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips = {'Bike02': '/Users/kierandonnelly/thesis/raw_clips/Bike02.mp4',\n",
    "        'Bike03': '/Users/kierandonnelly/thesis/raw_clips/Bike03.mp4',\n",
    "        'Bike05': '/Users/kierandonnelly/thesis/raw_clips/Bike05.mp4',\n",
    "        'Bike07': '/Users/kierandonnelly/thesis/raw_clips/Bike07.mp4',\n",
    "        'Bike08': '/Users/kierandonnelly/thesis/raw_clips/Bike08.mp4',\n",
    "        'Bike09': '/Users/kierandonnelly/thesis/raw_clips/Bike09.mp4',\n",
    "        'Ski01': '/Users/kierandonnelly/thesis/raw_clips/Ski01.mp4',\n",
    "        'Ski02': '/Users/kierandonnelly/thesis/raw_clips/Ski02.mp4',\n",
    "        'Ski03': '/Users/kierandonnelly/thesis/raw_clips/Ski03.mp4',\n",
    "        'Snowboard01': '/Users/kierandonnelly/thesis/raw_clips/Snowboard01.mp4',\n",
    "        'Sup01': '/Users/kierandonnelly/thesis/raw_clips/Sup01.mp4',\n",
    "        'Surf01': '/Users/kierandonnelly/thesis/raw_clips/Surf01.mp4',\n",
    "        'Wake01': '/Users/kierandonnelly/thesis/raw_clips/Wake01.mp4'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over videos in directory and run tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_track_test(input1, input2):\n",
    "    return(print(input1, input2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_list = []\n",
    "\n",
    "# iterate over clips\n",
    "for clip, clip_loc in clips.items(): \n",
    "    \n",
    "    # retrieve frame data for clip\n",
    "    frames = pd.read_csv(str('./frame_data/'+str(filename)+'.csv'))\n",
    "    \n",
    "    # iterate over tracker dictionary\n",
    "    for tracker, tracker_inst in trackers.items(): \n",
    "\n",
    "        # call tracking function\n",
    "        run_track_test(tracker_inst, clip_loc, frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import ground truth annotation data for each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_df = pd.read_csv(\"./frame_data/Bike05.csv\"); videos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = pd.read_csv(str('./frame_data/Bike03.csv'))\n",
    "frame_count = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006649</td>\n",
       "      <td>0.178487</td>\n",
       "      <td>0.067819</td>\n",
       "      <td>0.117021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.018617</td>\n",
       "      <td>0.186761</td>\n",
       "      <td>0.067154</td>\n",
       "      <td>0.112293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.034574</td>\n",
       "      <td>0.193853</td>\n",
       "      <td>0.064495</td>\n",
       "      <td>0.106383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.043883</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>0.068484</td>\n",
       "      <td>0.115839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.057181</td>\n",
       "      <td>0.210402</td>\n",
       "      <td>0.068484</td>\n",
       "      <td>0.105201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frame        x1        y1         w         h\n",
       "0    1.0  0.006649  0.178487  0.067819  0.117021\n",
       "1    2.0  0.018617  0.186761  0.067154  0.112293\n",
       "2    3.0  0.034574  0.193853  0.064495  0.106383\n",
       "3    4.0  0.043883  0.198582  0.068484  0.115839\n",
       "4    5.0  0.057181  0.210402  0.068484  0.105201"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1    0.034574\n",
       "y1    0.193853\n",
       "w     0.064495\n",
       "h     0.106383\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_bb = frames.loc[frames['frame'] == frame_count].squeeze()[1:]; init_bb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to implement tracking on one video sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this runs once per clip per tracker\n",
    "# lists declared and modified here pertain to one clip\n",
    "def run_track(tracker_inst, video_file, frames_df):\n",
    "    '''args: '''\n",
    "    \n",
    "    # initialise vars\n",
    "    frame_count = frames_df['frame'].min() # first frame containing g.t. object\n",
    "    miss_count, fp_count = 0, 0 # counters for different type of events\n",
    "    iou_list = [] # keep track of ious for each frame\n",
    "    \n",
    "    # define bb to initialise tracker with (x1, y1, w, h)\n",
    "    init_bb = frames_df.loc[frames_df['frame'] == frame_count].squeeze()[1:]\n",
    "    \n",
    "    # Initialize the video stream and pointer to output video file\n",
    "    vs = cv2.VideoCapture(video_file)\n",
    "    \n",
    "    # run until no more frames\n",
    "    while True:\n",
    "        # read the next frame from the file\n",
    "        grabbed, frame = vs.read()\n",
    "\n",
    "        # if no frame grabbed, reached end of clip\n",
    "        if not grabbed:\n",
    "            print (\"Not grabbed!\")\n",
    "            break\n",
    "\n",
    "        # will resize the frame for faster processing in our NN if applicable, and save the resolution\n",
    "        if resize is not 0:\n",
    "            frame = imutils.resize(frame, int(resize))\n",
    "\n",
    "        # start timer for fps metric\n",
    "        detectorTime = time.time()\n",
    "        \n",
    "        # initialize the writer\n",
    "        if writer is None:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"MP4V\")\n",
    "            fps = vs.get(5)\n",
    "            print(\"FPS = \" + str(fps))\n",
    "            writer = cv2.VideoWriter(\"output/\" + args[\"inputVideo\"] + \"_\" + \"_\" + args[\"tracker\"] + \".mp4\", fourcc, fps, (frame.shape[1], frame.shape[0]), True)\n",
    "        \n",
    "        if tracker is None:\n",
    "            # create tracker object\n",
    "            tracker = tracker_inst\n",
    "            \n",
    "            # initialise with some bounding box\n",
    "            tracker.init(frame, (init_bb[0], init_bb[1], init_bb[2], init_bb[3]))\n",
    "        else: \n",
    "            # tracker is already initialised\n",
    "            # update the tracker and grab the position of the tracked object\n",
    "            tracking, bbox = tracker.update(frame)\n",
    "            \n",
    "            # check if tracking, then draw bounding box\n",
    "            if tracking:\n",
    "                # Tracking success\n",
    "                p1 = (int(bbox[0]), int(bbox[1]))\n",
    "                p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "                cv2.rectangle(frame, p1, p2, (255, 0, 0), 2, 1)\n",
    "                cv2.putText(frame, text, (int(bbox[0]), int(bbox[1]) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (255, 0, 0), 2)\n",
    "                trackingFailed = False\n",
    "            else:\n",
    "                # Tracking failure\n",
    "                cv2.putText(frame, \"Tracking failure detected\", (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2)\n",
    "                trackingFailed = True\n",
    "\n",
    "            # logging purposes\n",
    "            if not trackingFailed:\n",
    "                print(\"[INFO] Tracker running at \" + str(1/(time.time() - trackerTime)) + \" fps\")\n",
    "                trackingFPS += 1/(time.time() - trackerTime)\n",
    "                trackingFrames += 1\n",
    "                \n",
    "        # increment frame counter\n",
    "        frame_count += 1\n",
    "        \n",
    "        # write the frame to disk\n",
    "        if writer is not None:\n",
    "            writer.write(frame)\n",
    "        \n",
    "        # TODO calculate metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "This section defines functions to compute the various evaluation metrics detailed in Chapter 3 in the report. The metrics to compute are as follows:\n",
    "- Recall: Correctly matched detections as proportion of total ground truth objects (of a sequence).\n",
    "- Precision/N-SODA: Correctly matched detections as a proportion of total detections (of a sequence).\n",
    "- FAF: Number of false alarms (incorrect detections) per frame averaged over a sequence.\n",
    "- SODP: Average overlap between true positives and ground truth.\n",
    "- SOTA: Combines false negatives and false positives.\n",
    "- SOTP: Overlap between the tracker output and the ground truth averaged over the matches.\n",
    "- TDE: Distance beetween the ground-truth annotation and the tracking result.\n",
    "- MT: The ground-truth trajectory is covered by the tracker output for more than 80% of its length.\n",
    "- ML: The ground-truth trajectory is covered by the tracker output for less than 20% of its length.\n",
    "- PT: The ground-truth trajectory is covered by the tracker output for between 20% and 80% of its length.\n",
    "- FM: Number of times that a ground-truth trajectory is interrupted in the tracking result, normalised over sequence.\n",
    "- RS: Ratio of tracks which correctly recover from short term occlusion.\n",
    "- RL: Ratio of tracks which correctly recover from long term occlusion.\n",
    "\n",
    "### Terminology\n",
    "- **Correctly-matched**: aka True Positive. Overlap between ground truth and tracker output is non-zero.\n",
    "- **Detection**: Tracker has some output for the frame.\n",
    "- **Miss**: aka False Negative. No output from tracker.\n",
    "- **False Positive**: Overlap between tracker output and ground truth is zero.\n",
    "- **Distance**: Euclidean distance between centroids of tracker output and ground truth.\n",
    "- **Covered**: Overlap is non-zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elements for whole sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-zero overlaps/correctly matched detections\n",
    "# cmd = \n",
    "\n",
    "# total ground truth objs in sequence/number of frames for a clip in the annotated data\n",
    "# in annotation table, groupby clip and then count rows for that clip\n",
    "# gto = \n",
    "\n",
    "# total detections made/tracker output non-zero\n",
    "# count tracking attempts made for a clip\n",
    "# td = \n",
    "\n",
    "# false positives/overlap of zero\n",
    "# fp = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elements for single frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapped Overlap Ratio (MOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapped overlap ratio\n",
    "def metric_mor(boxA, boxB):\n",
    "    # (x1,y1,x1 + w,y1 + h) -> (x1, y1, x2, y2)\n",
    "    boxA = [boxA[0], boxA[1], boxA[0] + boxA[2], boxA[1] + boxA[3]]\n",
    "    boxB = [boxB[0], boxB[1], boxB[0] + boxB[2], boxB[1] + boxB[3]]\n",
    "    \n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\n",
    "    # return the intersection over union value\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_recall(cmd, gto):\n",
    "    return cmd/gto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_precision(cmd, td):\n",
    "    return cmd/td"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False Alarms per Frame (FAF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_faf(fp, gto):\n",
    "    return fp/gto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Object Detection Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_sodp(sum_mor, n_frames):\n",
    "    # sum_mop = sum the mop() for each frame\n",
    "    # n_frames = len(sequence)\n",
    "    return sum_mor/n_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Area"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Thesis Env",
   "language": "python",
   "name": "thesis_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
